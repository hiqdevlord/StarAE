Optimization Project
====

##### Note that this folder is built for the Numerical Optimization course final project, instructed by Professor Margaret Wright in Courant Institute, New York Univeristy.

Introduction
---
The project will mostly focus on the training optimization for Autoencoder, which is a simple and widely used Neural Nets model. I will propose a series of results about optimizing Autoencoder in this two weeks (rather time-intensive).

Targets
---
SGD vs BFGS vs CG

general SGD vs SGD+momentum vs SGD+adastep vs SGD+mini-batch

mini-batch investigation for second-order methods

Scale of training set

Number of Layer

Results
---
TODO
